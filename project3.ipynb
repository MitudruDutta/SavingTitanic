{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56a9a696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TITANIC SURVIVAL PREDICTION - ADVANCED ML MODEL\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TITANIC SURVIVAL PREDICTION - ADVANCED ML MODEL\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2c31b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Loading data...\n",
      "Training set shape: (891, 12)\n",
      "Test set shape: (418, 11)\n",
      "Survival rate: 38.38%\n"
     ]
    }
   ],
   "source": [
    "# 1. LOAD DATA\n",
    "print(\"\\n1. Loading data...\")\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "print(f\"Training set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n",
    "print(f\"Survival rate: {train_df['Survived'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abcb00c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Performing feature engineering...\n",
      "Feature engineering completed! New shape: (891, 29)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2. Performing feature engineering...\")\n",
    "\n",
    "def feature_engineering(df):\n",
    "    \"\"\"Apply comprehensive feature engineering\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Extract Title from Name\n",
    "    df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Ms', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    # Family Size Features\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "    df['SmallFamily'] = ((df['FamilySize'] >= 2) & (df['FamilySize'] <= 4)).astype(int)\n",
    "    df['LargeFamily'] = (df['FamilySize'] >= 5).astype(int)\n",
    "    \n",
    "    # Age Features - Fill missing ages\n",
    "    for title in df['Title'].unique():\n",
    "        for pclass in df['Pclass'].unique():\n",
    "            mask = (df['Title'] == title) & (df['Pclass'] == pclass) & (df['Age'].isnull())\n",
    "            median_age = df[(df['Title'] == title) & (df['Pclass'] == pclass)]['Age'].median()\n",
    "            if pd.notna(median_age):\n",
    "                df.loc[mask, 'Age'] = median_age\n",
    "    \n",
    "    df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "    \n",
    "    # Age groups\n",
    "    df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 12, 18, 35, 60, 100], labels=['Child', 'Teen', 'Adult', 'Middle', 'Senior'])\n",
    "    df['IsChild'] = (df['Age'] < 16).astype(int)\n",
    "    df['IsElderly'] = (df['Age'] >= 60).astype(int)\n",
    "    \n",
    "    # Fare Features\n",
    "    df['Fare'].fillna(df['Fare'].median(), inplace=True)\n",
    "    df['FarePerPerson'] = df['Fare'] / df['FamilySize']\n",
    "    df['FareBin'] = pd.qcut(df['Fare'], 5, labels=['Very_Low', 'Low', 'Med', 'High', 'Very_High'], duplicates='drop')\n",
    "    \n",
    "    # Cabin Features\n",
    "    df['HasCabin'] = df['Cabin'].notna().astype(int)\n",
    "    df['CabinDeck'] = df['Cabin'].str[0]\n",
    "    df['CabinDeck'].fillna('Unknown', inplace=True)\n",
    "    \n",
    "    # Embarked\n",
    "    df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "    \n",
    "    # Ticket Features\n",
    "    df['TicketPrefix'] = df['Ticket'].str.split().str[0]\n",
    "    df['TicketPrefix'] = df['TicketPrefix'].apply(lambda x: 'Numeric' if x.isdigit() else x)\n",
    "    df['TicketLength'] = df['Ticket'].apply(len)\n",
    "    \n",
    "    # Interaction Features\n",
    "    df['Sex_Pclass'] = df['Sex'] + '_' + df['Pclass'].astype(str)\n",
    "    df['Age_Pclass'] = df['Age'] * df['Pclass']\n",
    "    df['Fare_Age'] = df['Fare'] / (df['Age'] + 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_processed = feature_engineering(train_df)\n",
    "test_processed = feature_engineering(test_df)\n",
    "\n",
    "print(f\"Feature engineering completed! New shape: {train_processed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "511da0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Preparing data for modeling...\n",
      "Training features shape: (891, 44)\n",
      "Test features shape: (418, 44)\n"
     ]
    }
   ],
   "source": [
    "# 3. PREPARE DATA FOR MODELING\n",
    "print(\"\\n3. Preparing data for modeling...\")\n",
    "\n",
    "categorical_features = ['Sex', 'Embarked', 'Title', 'AgeGroup', 'FareBin', 'CabinDeck', 'Sex_Pclass']\n",
    "numerical_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'IsAlone', \n",
    "                     'SmallFamily', 'LargeFamily', 'IsChild', 'IsElderly', 'HasCabin',\n",
    "                     'FarePerPerson', 'TicketLength', 'Age_Pclass', 'Fare_Age']\n",
    "\n",
    "# One-hot encode\n",
    "train_encoded = pd.get_dummies(train_processed[categorical_features + numerical_features], \n",
    "                               columns=categorical_features, drop_first=True)\n",
    "test_encoded = pd.get_dummies(test_processed[categorical_features + numerical_features], \n",
    "                              columns=categorical_features, drop_first=True)\n",
    "\n",
    "# Align columns\n",
    "train_encoded, test_encoded = train_encoded.align(test_encoded, join='left', axis=1, fill_value=0)\n",
    "\n",
    "X = train_encoded\n",
    "y = train_processed['Survived']\n",
    "X_test = test_encoded\n",
    "\n",
    "print(f\"Training features shape: {X.shape}\")\n",
    "print(f\"Test features shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81afc597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Training models with cross-validation...\n",
      "\n",
      "Cross-Validation Results:\n",
      "==================================================\n",
      "Logistic Regression : 0.8384 (+/- 0.0098)\n",
      "Random Forest       : 0.8361 (+/- 0.0069)\n",
      "Gradient Boosting   : 0.8193 (+/- 0.0178)\n",
      "XGBoost             : 0.8316 (+/- 0.0149)\n"
     ]
    }
   ],
   "source": [
    "# 4. MODEL TRAINING WITH CROSS-VALIDATION\n",
    "print(\"\\n4. Training models with cross-validation...\")\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=5, \n",
    "                                           min_samples_leaf=2, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=200, learning_rate=0.05, \n",
    "                                                    max_depth=5, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=5, \n",
    "                            random_state=42, eval_metric='logloss', use_label_encoder=False)\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = {}\n",
    "\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "    results[name] = scores\n",
    "    print(f\"{name:20s}: {scores.mean():.4f} (+/- {scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3304f7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Creating ensemble model...\n",
      "\n",
      "Ensemble Model CV Score: 0.8350 (+/- 0.0164)\n",
      "\n",
      "Training final ensemble model...\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# 5. ENSEMBLE MODEL\n",
    "print(\"\\n5. Creating ensemble model...\")\n",
    "\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=5, \n",
    "                                     min_samples_leaf=2, random_state=42)),\n",
    "        ('gb', GradientBoostingClassifier(n_estimators=200, learning_rate=0.05, \n",
    "                                         max_depth=5, random_state=42)),\n",
    "        ('xgb', XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=5, \n",
    "                             random_state=42, eval_metric='logloss', use_label_encoder=False)),\n",
    "        ('lr', LogisticRegression(max_iter=1000, random_state=42))\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "ensemble_scores = cross_val_score(ensemble_model, X, y, cv=cv, scoring='accuracy')\n",
    "print(f\"\\nEnsemble Model CV Score: {ensemble_scores.mean():.4f} (+/- {ensemble_scores.std():.4f})\")\n",
    "\n",
    "# Train final model\n",
    "print(\"\\nTraining final ensemble model...\")\n",
    "ensemble_model.fit(X, y)\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4b4f557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6. Analyzing feature importance...\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "          feature  importance\n",
      "         Title_Mr    0.108617\n",
      "         Sex_male    0.098332\n",
      "       Age_Pclass    0.083254\n",
      "         Fare_Age    0.080096\n",
      "    FarePerPerson    0.068088\n",
      "             Fare    0.065698\n",
      "              Age    0.057195\n",
      "Sex_Pclass_male_3    0.039847\n",
      "     TicketLength    0.031675\n",
      "        Title_Mrs    0.030020\n"
     ]
    }
   ],
   "source": [
    "# 6. FEATURE IMPORTANCE\n",
    "print(\"\\n6. Analyzing feature importance...\")\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39c16e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7. Making predictions...\n",
      "Predictions completed!\n",
      "Predicted survival rate: 36.36%\n"
     ]
    }
   ],
   "source": [
    "# 7. MAKE PREDICTIONS\n",
    "print(\"\\n7. Making predictions...\")\n",
    "\n",
    "predictions = ensemble_model.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_df['PassengerId'],\n",
    "    'Survived': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Predictions completed!\")\n",
    "print(f\"Predicted survival rate: {predictions.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de23d14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL PERFORMANCE SUMMARY\n",
      "============================================================\n",
      "\n",
      "Training Set Size: 891\n",
      "Test Set Size: 418\n",
      "Number of Features: 44\n",
      "\n",
      "Cross-Validation Accuracy: 0.8350 (+/- 0.0164)\n",
      "\n",
      "Predicted Survivors: 152 (36.36%)\n",
      "Predicted Non-Survivors: 266 (63.64%)\n",
      "\n",
      "============================================================\n",
      "Submission file 'submission.csv' created successfully!\n",
      "============================================================\n",
      "\n",
      "First 10 predictions:\n",
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         0\n",
      "4          896         1\n",
      "5          897         0\n",
      "6          898         0\n",
      "7          899         0\n",
      "8          900         1\n",
      "9          901         0\n"
     ]
    }
   ],
   "source": [
    "# 8. SUMMARY\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTraining Set Size: {len(train_df)}\")\n",
    "print(f\"Test Set Size: {len(test_df)}\")\n",
    "print(f\"Number of Features: {X.shape[1]}\")\n",
    "print(f\"\\nCross-Validation Accuracy: {ensemble_scores.mean():.4f} (+/- {ensemble_scores.std():.4f})\")\n",
    "print(f\"\\nPredicted Survivors: {predictions.sum()} ({predictions.mean():.2%})\")\n",
    "print(f\"Predicted Non-Survivors: {len(predictions) - predictions.sum()} ({1-predictions.mean():.2%})\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Submission file 'submission.csv' created successfully!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nFirst 10 predictions:\")\n",
    "print(submission.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
